{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d0d3b93",
   "metadata": {},
   "source": [
    "# Relocation Destination Personalization Machination Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8bf227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aed27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import your quiz results\n",
    "quiz = pd.read_excel(\"RDPM_Quiz.xlsx\", sheet_name=\"Upload\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7912c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get county data\n",
    "github_url = \"https://raw.githubusercontent.com/rabader/relocation-personalization/main/data/\"\n",
    "\n",
    "FIPS_d = pd.read_csv(github_url + \"processed/FIPS_ref.csv\").set_index('FIPS')\n",
    "rel_d = pd.read_csv(github_url + \"processed/Religion_dataset.csv\").set_index('FIPS')\n",
    "sd_d = pd.read_csv(github_url + \"interim/School_2018_imputed.csv\")\n",
    "ter_d = pd.read_csv(github_url + \"processed/Terrain_dataset.csv\").set_index('FIPS')\n",
    "wth_d = pd.read_csv(github_url + \"processed/Weather_etc_State_dataset.csv\")\n",
    "acs_d = pd.read_csv(github_url + \"interim/ACS_2020_imputed.csv\").set_index('FIPS')\n",
    "hth_d = pd.read_csv(github_url + \"interim/health_imputed.csv\").set_index('FIPS')\n",
    "fbi_d = pd.read_csv(github_url + \"interim/fbi_imputed.csv\").set_index('FIPS')\n",
    "pol_d = pd.read_csv(github_url + \"processed/Politics.csv\").set_index('FIPS')\n",
    "tax_d = pd.read_csv(github_url + \"processed/Taxes.csv\")\n",
    "\n",
    "print(\"FIPS: \" + str(len(FIPS_d)), '\\n', \"Religion: \" + str(len(rel_d)), '\\n', \"School District: \" + str(len(sd_d)),\n",
    "    '\\n', \"Terrain: \" + str(len(ter_d)), '\\n', \"Weather: \" + str(len(wth_d)), '\\n', \"Census: \" + str(len(acs_d)),\n",
    "      '\\n', \"Health: \" + str(len(hth_d)), '\\n', \"Crime: \" + str(len(fbi_d)), '\\n', \"Politics: \" + str(len(pol_d)),\n",
    "     \"Taxes: \" + str(len(tax_d)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a0c828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 'Scores' column with 0 penalty points\n",
    "dfs = [FIPS_d, rel_d, sd_d, ter_d, wth_d, acs_d, hth_d, fbi_d, pol_d, tax_d]\n",
    "\n",
    "for df in dfs:\n",
    "    df['Scores'] = 0 # create empty Scores column for all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3645fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove Alaska and Puerto Rico from datasets\n",
    "dfs = [df[(df['State']!='Alaska') & (df['State']!='Puerto Rico')] for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52973586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace dfs with dfs that have locations removed\n",
    "FIPS_d = dfs[0]\n",
    "rel_d = dfs[1]\n",
    "sd_d = dfs[2]\n",
    "ter_d = dfs[3]\n",
    "wth_d = dfs[4]\n",
    "acs_d = dfs[5]\n",
    "hth_d = dfs[6]\n",
    "fbi_d = dfs[7]\n",
    "pol_d = dfs[8]\n",
    "tax_d = dfs[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8ffb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty importance list for all data\n",
    "dfs_str = ['FIPS_d', 'rel_d', 'sd_d', 'ter_d', 'wth_d', 'acs_d', 'hth_d', 'fbi_d', 'pol_d', 'tax_d']\n",
    "\n",
    "for df in dfs_str:\n",
    "    exec(df+'_imp = []')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66098312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create grader function (0 penality if at least/most)\n",
    "def grader(df, response_row, actual):\n",
    "    \n",
    "    if quiz.iloc[response_row,1] == \"At least\":\n",
    "        score_series = df[actual].apply(lambda x: max(quiz.iloc[response_row,2] - x, 0)**2 * quiz.iloc[response_row,3])\n",
    "    elif quiz.iloc[response_row,1] == \"At most:\":\n",
    "        score_series = df[actual].apply(lambda x: max(x - quiz.iloc[response_row,2], 0)**2 * quiz.iloc[response_row,3])\n",
    "    else: \n",
    "        score_series = abs(quiz.iloc[response_row,2] - df[actual])**2 * quiz.iloc[response_row,3]\n",
    "    \n",
    "    imp_score = quiz.iloc[response_row,3] # importance score of this question\n",
    "    \n",
    "    return score_series, imp_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d466dfc7",
   "metadata": {},
   "source": [
    "## Religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d3ac24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel) blanks in this dataset are equal to zero\n",
    "rel_d = rel_d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868aeaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel-1) I prefer the % of the population adhering to any religion to be:\n",
    "score, imp_score = grader(rel_d, 47, 'All Religious Adherence Rate D') \n",
    "rel_d['Scores'] += score \n",
    "rel_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53e419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel-2) I prefer there to be a significant presence of this religious group:\n",
    "# dividing by 25 because score can be 0 to 100, but worst possible score in 5 multiple choice is off by 4\n",
    "# so if 0 presence of that religion should score 4, then 100/25 = 4\n",
    "rel2_response = rel_d.loc[:,str(quiz.iloc[48,2])]\n",
    "rel_d['Scores'] += (((100 - rel2_response)/25)**2) * quiz.iloc[48,3]\n",
    "rel_d_imp.append(quiz.iloc[48,3]) # imp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f37bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add rel scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(rel_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e22a29",
   "metadata": {},
   "source": [
    "## School District"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f99dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD) first questions\n",
    "sd_cats = ['SchoolDigger Number of Stars Elementary', 'SchoolDigger Number of Stars Middle', \n",
    "          'SchoolDigger Number of Stars High', 'Student/Teacher Ratio D', 'Number All Students D']\n",
    "\n",
    "start_loc = 35\n",
    "for sd_cat in sd_cats:\n",
    "    score, imp_score = grader(sd_d, start_loc + sd_cats.index(sd_cat), sd_cat)\n",
    "    sd_d['Scores'] += score\n",
    "    sd_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c29026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD-6) For racial distribution, I prefer there to be AT LEAST this percentage of each race:\n",
    "races = ['% Asian students', '% Black students', '% Hawaiian Native/Pacific Islander students', '% Hispanic students',\n",
    "           '% American Indian/Alaska Native students', '% students with Two or More Races', '% White students']\n",
    "\n",
    "for race in races:\n",
    "    sd_d['Scores'] += sd_d[race].apply(lambda x: max(((quiz.iloc[races.index(race)+40,2] - x)/25)**2,0) * quiz.iloc[46,3])\n",
    "sd_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374fee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD) get lowest penalty score district for each county, reset series to dataframe, reset index\n",
    "sd_d_grouped = sd_d.groupby(['County','State'])['Scores'].min().to_frame().reset_index() # get district with lowest penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6602fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SD) add grouped SD data to FIPS Scores through join\n",
    "FIPS_d = FIPS_d.reset_index()\n",
    "sd_d_scores = sd_d_grouped[['County','State','Scores']].rename({'Scores':'sd_Scores'}, axis='columns')\n",
    "FIPS_d = pd.merge(FIPS_d, sd_d_scores, left_on=['County','State'], right_on=['County','State'], how='left')\n",
    "FIPS_d['Scores'] += FIPS_d['sd_Scores']\n",
    "del FIPS_d['sd_Scores']\n",
    "FIPS_d = FIPS_d.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f09fb8e",
   "metadata": {},
   "source": [
    "## Terrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2d6844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ter) Look at only the most recent completed year but keep entirity for time series analysis\n",
    "ter_d_all = ter_d.copy()\n",
    "ter_d = ter_d_all[ter_d['Year']==2011]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55366a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ter-1) For terrain, I prefer there to be AT LEAST this percentage of each terrain:\n",
    "terrains = ['Big city', 'Farmland', 'Forests', 'Houses with lots of land', 'Open fields', 'Open water', \n",
    "            'Perennial ice/snow', 'Rock/Sand/Clay', 'Suburbia', 'Wetlands']\n",
    "\n",
    "for terrain in terrains:\n",
    "    ter_d['Scores'] += ter_d[terrain].apply(\n",
    "        lambda x: max(((quiz.iloc[terrains.index(terrain)+14,2] - x)/25)**2,0) * quiz.iloc[terrains.index(terrain)+14,3])\n",
    "ter_d_imp.append(quiz.iloc[terrains.index(terrain)+14,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84178bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ter) add ter scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(ter_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e557a41",
   "metadata": {},
   "source": [
    "## State Level Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12233549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wth) first questions\n",
    "wth_cats = ['Winter Avg temp (F) D', 'Summer Avg temp (F) D', 'Avg Yearly Rainfall (in) D', 'Avg Yearly Snowfall (in) D',\n",
    "          'Avg Hours Sunshine Daily D', 'Avg Clear Days D', 'Avg Days with Snow D']\n",
    "\n",
    "start_loc = 28\n",
    "for wth_cat in wth_cats:\n",
    "    score, imp_score = grader(wth_d, start_loc + wth_cats.index(wth_cat), wth_cat)\n",
    "    wth_d['Scores'] += score\n",
    "    wth_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf32d96e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wth) add state Wth data to FIPS Scores through join\n",
    "FIPS_d = FIPS_d.reset_index()\n",
    "wth_d_scores = wth_d[['State','Scores']].rename({'Scores':'wth_Scores'}, axis='columns')\n",
    "FIPS_d = pd.merge(FIPS_d, wth_d_scores, left_on='State', right_on='State', how='left')\n",
    "FIPS_d['Scores'] += FIPS_d['wth_Scores']\n",
    "del FIPS_d['wth_Scores']\n",
    "FIPS_d = FIPS_d.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d7cda8",
   "metadata": {},
   "source": [
    "## Census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1190b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acs) first questions\n",
    "acs_cats = ['% Pop Density D', '% Children Under 10 D', '% Children 10 and Older D', '% Couples that are Same-Sex D',\n",
    "           '% Population Over 25 with at Least a Bachelor Degree D', \n",
    "           '% Civilian Population 18 Years and Over that is a Veteran D',\n",
    "           '% Foreign Born D']\n",
    "\n",
    "start_loc = 0\n",
    "for acs_cat in acs_cats:\n",
    "    score, imp_score = grader(acs_d, start_loc + acs_cats.index(acs_cat), acs_cat)\n",
    "    acs_d['Scores'] += score\n",
    "    acs_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae2237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS-8) For racial distribution, I prefer the percentage of each race to be AT LEAST:\n",
    "races = ['% Asian', '% Black', '% Hawaiian or Pacific Islander', '% Hispanic', '% Native American', \n",
    "         '% Two or More Races', '% White', '% Other Race']\n",
    "\n",
    "for race in races:\n",
    "    acs_d['Scores'] += acs_d[race].apply(lambda x: max(((quiz.iloc[races.index(race)+7,2] - x)/25)**2,0) * quiz.iloc[14,3])\n",
    "acs_d_imp.append(quiz.iloc[14,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e3d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acs) last questions\n",
    "acs_cats = ['Median Household Income D', 'Median Gross Rent D', 'Average Commute to Work D']\n",
    "\n",
    "start_loc = 15\n",
    "for acs_cat in acs_cats:\n",
    "    score, imp_score = grader(acs_d, start_loc + acs_cats.index(acs_cat), acs_cat)\n",
    "    acs_d['Scores'] += score\n",
    "    acs_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55029cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACS) add acs scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(acs_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d1a7fe",
   "metadata": {},
   "source": [
    "## Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hth) Look at only the most recent completed year but keep entirity for time series analysis\n",
    "hth_d_all = hth_d.copy()\n",
    "hth_d = hth_d_all[hth_d['Year']==2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e56ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hth) all questions\n",
    "hth_cats = ['Primary Care Physicians Per 100,000 Population D',\n",
    "'Mental Health Providers Per 100,000 Population D',\n",
    "'Dentists Per 100,000 Population D',\n",
    "'Percent Adults With Limited Access To Doctor Due To Costs D',\n",
    "'Percent Persons With Limited Access To Healthy Foods D',\n",
    "'Percent Physically Inactive Persons D',\n",
    "'Percent Obese Persons Adults D',\n",
    "'Percent Adults That Report Fair Or Poor Health D',\n",
    "'Percent Current Adult Smokers D',\n",
    "'Percent Drinking Adults D',\n",
    "'STI Rate Per 100,000 Population D',\n",
    "'Child Mortality Rate Per 100,000 Population D',\n",
    "'Teen Births Rate Per 1,000 Population D',\n",
    "'Infant Mortality Rate Per 1,000 Live Births D',\n",
    "'Percent Low Birthweight Births (<2.5Kg) D']\n",
    "\n",
    "start_loc = 49\n",
    "for hth_cat in hth_cats:\n",
    "    score, imp_score = grader(hth_d, start_loc + hth_cats.index(hth_cat), hth_cat)\n",
    "    hth_d['Scores'] += score\n",
    "    hth_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a90454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hth) add hth scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(hth_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bf07b8",
   "metadata": {},
   "source": [
    "## Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c13b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBI) Look at only the most recent completed year but keep entirity for time series analysis\n",
    "fbi_d_all = fbi_d.copy()\n",
    "fbi_d = fbi_d_all[fbi_d['Year']==2017]\n",
    "fbi_d.index = fbi_d.index.astype(int, copy=False) # change index type to int to match FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FBI) all questions\n",
    "fbi_cats = ['Violent Crimes Rate D','Property Crimes Rate D']\n",
    "\n",
    "start_loc = 64\n",
    "for fbi_cat in fbi_cats:\n",
    "    score, imp_score = grader(fbi_d, start_loc + fbi_cats.index(fbi_cat), fbi_cat)\n",
    "    fbi_d['Scores'] += score\n",
    "    fbi_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a42ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fbi) add fbi scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(fbi_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2daae64",
   "metadata": {},
   "source": [
    "## Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bc2672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pol) blanks in this dataset are equal to zero\n",
    "pol_d = pol_d.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe937726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pol) Look at only the most recent completed year but keep entirity for time series analysis\n",
    "pol_d_all = pol_d.copy()\n",
    "pol_d = pol_d_all[pol_d['Year']==2020]\n",
    "pol_d.index = pol_d.index.astype(int, copy=False) # change index type to int to match FIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ba153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pol) I prefer there to be a significant presence of this political group:\n",
    "pol_response = pol_d.loc[:,str(quiz.iloc[66,2])]\n",
    "pol_d['Scores'] += (((100 - pol_response)/25)**2) * quiz.iloc[66,3]\n",
    "pol_d_imp.append(quiz.iloc[66,3]) # imp_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec2ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pol) add pol scores to FIPS_d score total\n",
    "FIPS_d['Scores'] = FIPS_d['Scores'].add(pol_d['Scores'], fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07f1b3e",
   "metadata": {},
   "source": [
    "## State Taxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc6fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tax) all questions\n",
    "tax_cats = ['State and Mean Local Sales Tax D','Income Tax (Lowest Bracket) D',\n",
    "            'Income Tax (Highest Bracket) D', 'Median Property Tax D']\n",
    "\n",
    "start_loc = 67\n",
    "for tax_cat in tax_cats:\n",
    "    score, imp_score = grader(tax_d, start_loc + tax_cats.index(tax_cat), tax_cat)\n",
    "    tax_d['Scores'] += score\n",
    "    tax_d_imp.append(imp_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f04b930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tax) add state tax data to FIPS Scores through join\n",
    "tax_d_scores = tax_d[['State','Scores']].rename({'Scores':'tax_Scores'}, axis='columns')\n",
    "\n",
    "FIPS_d = FIPS_d.reset_index()\n",
    "FIPS_d = pd.merge(FIPS_d, tax_d_scores, left_on=['State'], right_on=['State'], how='left')\n",
    "FIPS_d['Scores'] += FIPS_d['tax_Scores']\n",
    "del FIPS_d['tax_Scores']\n",
    "FIPS_d = FIPS_d.set_index('FIPS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c8170d",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db906d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "FIPS_d.sort_values(by='Scores', inplace=True)\n",
    "FIPS_d = FIPS_d.round({'Scores':2})\n",
    "FIPS_d.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24765e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# radar chart of category importance\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "categories = ['Census', 'Terrain', 'Weather', 'School District', 'Religion', 'Health', 'Crime', 'Politics', 'Taxes']\n",
    "importance_means = [np.mean(acs_d_imp), np.mean(ter_d_imp), np.mean(wth_d_imp), np.mean(sd_d_imp), \n",
    "                    np.mean(rel_d_imp), np.mean(hth_d_imp), np.mean(fbi_d_imp), np.mean(pol_d_imp),\n",
    "                    np.mean(tax_d_imp)]\n",
    "\n",
    "imp_viz_df = pd.DataFrame(dict(Category = categories, Mean_Importance = importance_means))\n",
    "\n",
    "imp_viz = px.line_polar(imp_viz_df, r='Mean_Importance', theta='Category', line_close=True,\n",
    "                       title=\"Mean Importance by Category\")\n",
    "imp_viz.update_traces(fill='toself')\n",
    "imp_viz.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
